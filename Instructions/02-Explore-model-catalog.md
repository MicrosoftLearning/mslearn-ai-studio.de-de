---
lab:
  title: Ausw√§hlen und Bereitstellen eines Sprachmodells
  description: 'Generative KI-Anwendungen basieren auf einem oder mehreren Sprachmodellen. Erfahren Sie, wie Sie geeignete Modelle f√ºr Ihr generatives KI-Projekt finden und ausw√§hlen.'
---

# Ausw√§hlen und Bereitstellen eines Sprachmodells

Der Modellkatalog von Azure KI Foundry dient als zentrales Repository, in dem Sie eine Vielzahl von Modellen erforschen und verwenden k√∂nnen, was die Erstellung Ihres generativen KI-Szenarios erleichtert.

In dieser √úbung erkunden Sie den Modellkatalog im Azure AI Foundry-Portal und vergleichen potenzielle Modelle f√ºr eine generative KI-Anwendung, die bei der L√∂sung von Problemen hilft.

Diese √úbung dauert ungef√§hr **25**¬†Minuten.

## Erstellen eines Azure KI-Hubs und eines Projekts

Ein Azure¬†KI-Hub bietet einen Arbeitsbereich f√ºr die Zusammenarbeit, in dem Sie ein oder mehrere *Projekte* definieren k√∂nnen. Erstellen Sie uns ein Projekt und ein Azure KI-Hub.

1. √ñffnen Sie in einem Webbrowser unter `https://ai.azure.com` das [Azure KI Foundry-Portal](https://ai.azure.com) und melden Sie sich mit Ihren Azure-Anmeldeinformationen an. Schlie√üen Sie alle Tipps oder Schnellstartbereiche, die beim ersten Anmelden ge√∂ffnet werden, und verwenden Sie bei Bedarf das **Azure AI Foundry-Logo** oben links, um zur Startseite zu navigieren, die √§hnlich wie die folgende Abbildung aussieht:

    ![Screenshot des Azure KI Foundry-Portals.](./media/ai-foundry-home.png)

1. W√§hlen Sie auf der Startseite **+ Projekt erstellen**.
1. Geben Sie im Assistenten **Projekt erstellen** einen passenden Projektnamen ein (z.B. `my-ai-project`) und w√§hlen Sie, falls ein vorhandener Hub vorgeschlagen wird, die Option zum Erstellen eines neuen. √úberpr√ºfen Sie dann die Azure-Ressourcen, die automatisch erstellt werden, um Ihren Hub und Ihr Projekt zu unterst√ºtzen.
1. W√§hlen Sie **Anpassen** aus und legen Sie die folgenden Einstellungen f√ºr Ihren Hub fest:
    - **Hubname**: *Ein eindeutiger Name ‚Äì z. B. `my-ai-hub`.*
    - **Abonnement:** *Geben Sie Ihr Azure-Abonnement an.*
    - **Ressourcengruppe**: *Erstellen Sie eine neue Ressourcengruppe mit einem eindeutigen Namen (z.B. `my-ai-resources`), oder w√§hlen Sie eine bestehende aus.*
    - **Standort**: W√§hlen Sie **Hilfe bei der Auswahl** aus, w√§hlen Sie dann **gpt-4** im Fenster der Standorthilfe aus und verwenden Sie die empfohlene Region\*.
    - **Verbinden von Azure KI Services oder Azure OpenAI**: *Erstellen Sie eine neue KI Services-Ressource mit einem geeigneten Namen (z.B. `my-ai-services`) oder verwenden Sie eine vorhandene.*
    - **Azure¬†KI-Suche verbinden**: Verbindung √ºberspringen

    > \* Die Modellquoten werden auf der Ebene des Mandanten durch regionale Quoten eingeschr√§nkt. Wenn sp√§ter in der √úbung ein Kontingentlimit erreicht wird, besteht eventuell die M√∂glichkeit, eine andere Ressource in einer anderen Region zu erstellen.

1. Klicken Sie auf **Weiter**, um Ihre Konfiguration zu √ºberpr√ºfen. Klicken Sie auf **Erstellen** und warten Sie, bis der Vorgang abgeschlossen ist.
1. Sobald Ihr Projekt erstellt wurde, schlie√üen Sie alle angezeigten Tipps und √ºberpr√ºfen Sie die Projektseite im Azure AI Foundry-Portal, die in etwa wie in der folgenden Abbildung aussehen sollte:

    ![Screenshot eines Azure KI-Projekts im Azure AI Foundry-Portal.](./media/ai-foundry-project.png)

## Konfigurieren der Azure AI Inference-Dienstbereitstellung

Es gibt mehrere Optionen f√ºr die Bereitstellung von Modellen im Azure AI Foundry-Portal. In dieser √úbung verwenden Sie die Bereitstellungsoption **Azure KI-Modellinferenz**, die sowohl *Azure OpenAI*-Modelle als auch *Model-as-a-Service*-Modelle aus dem Azure AI Foundry-Modellkatalog unterst√ºtzt. Da alle Modelle auf einem gemeinsamen Endpunkt bereitgestellt werden, der von Ihrer Azure AI Services-Ressource gehostet wird, ist es einfach, beim Testen zwischen Modellen zu wechseln, um Verhalten und Leistung zu vergleichen.

1. Verwenden Sie auf der Symbolleiste oben rechts auf der Azure AI Foundry-Projektseite das Symbol **Vorschaufeatures** (üì£), um Vorschaufeatures anzuzeigen.
1. Stellen Sie sicher, dass die Funktion **Modelle im Azure KI-Modellinferenz-Service bereitstellen** aktiviert ist. Schlie√üen Sie dann den Bereich **Vorschaufeature**.

## √úberpr√ºfen von Modelldetails und Benchmarks

Um Ihnen bei der Auswahl eines Modells zu helfen, k√∂nnen Sie sich die Modellbeschreibungen und Benchmarks ansehen, um festzustellen, welches Modell ihren Anforderungen am besten entspricht.

1. W√§hlen Sie im Azure KI Foundry-Projektportal im Men√ºbereich auf der linken Seite **Modellkatalog** aus.
1. Suchen Sie auf der Startseite des Modellkatalogs nach `gpt-4`, um das Chat-Abschlussmodell **gpt-4** zu finden.

    ![Screenshot einer Suche nach ‚Äûgpt-4‚Äú im Modellkatalog.](./media/model-catalog-search-gpt4.png)

1. W√§hlen Sie das Modell **gpt-4** aus, um seine Details anzuzeigen. Lesen Sie die Beschreibung, und √ºberpr√ºfen Sie die anderen informationen, die auf der Seite verf√ºgbar sind.

    ![Screenshot der Detailseite des gpt-4-Modells.](./media/gpt4-details.png)

1. Zeigen Sie auf der Seite **gpt-4** die Registerkarte **Benchmarks** an, um zu sehen, wie das Modell im Vergleich zu einigen Standardleistungs-Benchmarks bei anderen Modellen abschneidet, die in √§hnlichen Szenarien verwendet werden.

    ![Screenshot der Seite ‚Äûgpt-4-Modell-Benchmarks‚Äú.](./media/gpt4-benchmarks.png)

1. Verwenden Sie den Pfeil ‚ÄûZur√ºck‚Äú (**&larr;**) neben dem Seitentitel **gpt-4**, um zur Startseite des Modellkatalogs zur√ºckzukehren.
1. Suchen Sie im Modellkatalog nach `Phi-3.5-mini-instruct` und sehen Sie sich die Details und Benchmarks f√ºr das Modell **Phi-3.5-mini-instruct** an.

## Vergleichen von Modellen

Sie haben zwei verschiedene Modelle √ºberpr√ºft, von denen beide verwendet werden k√∂nnen, um eine generative KI-Chatanwendung zu implementieren. Jetzt vergleichen wir die Metriken f√ºr diese beiden Modelle visuell.

1. Kehren Sie zur Startseite des **Modellkatalogs** zur√ºck.
1. W√§hlen Sie **Modelle vergleichen** aus. Ein visuelles Diagramm f√ºr den Modellvergleich wird mit einer Auswahl g√§ngiger Modelle angezeigt.

    ![Screenshot der Modellvergleichsseite.](./media/compare-models.png)

1. Beachten Sie im Bereich **Modelle zum Vergleichen** auf der linken Seite, dass Sie beliebte Aufgaben ausw√§hlen k√∂nnen, z. B. *Fragen und Antworten*, um automatisch h√§ufig verwendete Modelle f√ºr bestimmte Aufgaben auszuw√§hlen.
1. Verwenden Sie das Symbol **Alle Modelle l√∂schen** (&#128465;), um alle vordefinierten Modelle zu entfernen.
1. Verwenden Sie die Schaltfl√§che **+Modell zum Vergleichen**, um der Liste das Modell **gpt-4** hinzuzuf√ºgen. Verwenden Sie dann dieselbe Schaltfl√§che, um der Liste das Modell **Phi-3.5-mini-instruct** hinzuzuf√ºgen.
1. √úberpr√ºfen Sie das Diagramm, das die Modelle basierend auf dem **Qualit√§tsindex** (eine standardisierte Bewertung, die die Modellqualit√§t angibt) und den **Kosten** vergleicht. Sie k√∂nnen die spezifischen Werte f√ºr ein Modell anzeigen, indem Sie den Mauszeiger √ºber den entsprechenden Punkt im Diagramm bewegen.

    ![Screenshot des Modellvergleichsdiagramms f√ºr gpt-4 und Phi-3.5-mini-instruct.](./media/comparison-chart.png)

1. W√§hlen Sie im Dropdown-Men√º **X-Achse** unter **Qualit√§t** die folgenden Metriken aus und betrachten Sie jedes resultierende Diagramm, bevor Sie zum n√§chsten wechseln:
    - Genauigkeit
    - Koh√§renz
    - Gel√§ufigkeit
    - Relevance

## Bereitstellen von Modellen

Nachdem Sie Ihre Optionen nun mithilfe von Modell-Benchmarks untersucht haben, k√∂nnen Sie Sprachmodelle bereitstellen. Sie k√∂nnen den Modellkatalog durchsuchen und von dort aus bereitstellen oder ein Modell √ºber die Seite**Bereitstellungen** zur Verf√ºgung stellen. Lassen Sie uns beide Optionen erkunden.

### Bereitstellen eines Modells aus dem *Modellkatalog*

Beginnen wir mit der Bereitstellung eines Modells aus dem Modellkatalog. Sie k√∂nnen diese Option bevorzugen, wenn Sie verschiedene verf√ºgbare Modelle pr√ºfen m√∂chten.

1. Kehren Sie zur Startseite des **Modellkatalogs** zur√ºck.
1. Suchen Sie wie zuvor das `gpt-4` Modell und w√§hlen Sie es aus.
1. W√§hlen Sie auf der Seite **gpt-4** die Option **Bereitstellen** aus und stellen Sie das Modell mit den folgenden Einstellungen bereit, indem Sie in den Bereitstellungsdetails die Option **Anpassen** ausw√§hlen:
1. Stellen Sie das Modell mit den folgenden Einstellungen bereit, indem Sie **Anpassen** in den Bereitstellungsdetails w√§hlen:
    - **Bereitstellungsname**: *Ein eindeutiger Name f√ºr Ihre Modellbereitstellung, zum Beispiel `gpt-4`.*
    - **Bereitstellungstyp**: Standard
    - **Modellversion**: 0613
    - **Verbundene AI-Ressource**: *W√§hlen Sie Ihre Azure OpenAI-Ressourcenverbindung*
    - **Ratenbegrenzung f√ºr Token pro Minute (Tausender)**: 5.000
    - **Inhaltsfilter**: StandardV2 
    - **Dynamische Quote aktivieren**: Deaktiviert
      
    > **Hinweis:** Durch das Verringern des TPM wird die √úberlastung des Kontingents vermieden, das in dem von Ihnen verwendeten Abonnement verf√ºgbar ist. 5.000 TPM reicht f√ºr die in dieser √úbung verwendeten Daten aus.

1. Warten Sie, bis die Bereitstellung abgeschlossen ist.

### Bereitstellen eines Modells √ºber *Modelle + Endpunkte*

Wenn Sie bereits genau wissen, welches Modell Sie bereitstellen m√∂chten, ziehen Sie es vielleicht vor, dies √ºber **Modelle + Endpunkte** zu tun.

1. W√§hlen Sie in der Navigationsleiste auf der linken Seite im Bereich **Meine Assets** die Option **Modelle + Endpunkte** aus.
1. W√§hlen Sie auf der Registerkarte **Modellbereitstellungen** in der Dropdownliste **+ Modell bereitstellen** die Option **Basismodell bereitstellen** aus. Suchen Sie dann nach `Phi-3.5-mini-instruct` und best√§tigen Sie Ihre Auswahl.
1. Stimmen Sie der Modelllizenz zu.
1. Stellen Sie ein **Phi-3.5-mini-instruct** -Modell mit den folgenden Einstellungen bereit:
    - **Bereitstellungsname**: *Ein eindeutiger Name f√ºr Ihre Modellbereitstellung, zum Beispiel `Phi-3.5-mini-instruct`*
    - **Bereitstellungstyp**: Globaler Standard
    - **Bereitstellungsdetails**: *Verwenden der Standardeinstellungen.*

1. Warten Sie, bis die Bereitstellung abgeschlossen ist.

## Testen von Modellen im Chat-Playground

Nachdem wir nun zwei Modelle zum Vergleichen haben, sehen wir uns an, wie sich die Modelle in einer Unterhaltungsinteraktion verhalten.

### Vorbereiten des Chats

1. W√§hlen Sie in der Navigationsleiste **Playgrounds** aus. W√§hlen Sie dann den **Chatplayground** aus.
1. Legen Sie im Bereich **Setup** im Feld **Dem Modell Anweisungen und Kontext geben** die Systemansage auf `You are an AI assistant that helps solve problems.` fest
1. W√§hlen Sie **√Ñnderungen √ºbernehmen** aus.

### Chatten mit dem *gpt-4*-Modell

W√§hlen Sie im Bereich **Setup** Ihr *gpt-4*-Modell aus.
1. Geben Sie im Chatfenster die folgende Abfrage ein:

    ```
    I have a fox, a chicken, and a bag of grain that I need to take over a river in a boat. I can only take one thing at a time. If I leave the chicken and the grain unattended, the chicken will eat the grain. If I leave the fox and the chicken unattended, the fox will eat the chicken. How can I get all three things across the river without anything being eaten?
    ```

1. Zeigen Sie die Antwort an. Geben Sie dann die folgende Nachverfolgungsabfrage ein:

    ```
    Explain your reasoning.
    ```

### Chatten mit dem *Phi-3.5*-Modell

1. W√§hlen Sie im Bereich **Setup** Ihr *Phi-3.5*-Modell aus.
1. Stellen Sie sicher, dass eine neue Chatsitzung gestartet wird, bevor Sie die gleichen Prompts wiederholen, die Sie zuvor zum Testen des gpt-4-Modells verwendet haben.
1. Geben Sie im Chatfenster die folgende Abfrage ein:

    ```
    I have a fox, a chicken, and a bag of grain that I need to take over a river in a boat. I can only take one thing at a time. If I leave the chicken and the grain unattended, the chicken will eat the grain. If I leave the fox and the chicken unattended, the fox will eat the chicken. How can I get all three things across the river without anything being eaten?
    ```

1. Zeigen Sie die Antwort an. Geben Sie dann die folgende Nachverfolgungsabfrage ein:

    ```
    Explain your reasoning.
    ```

### Durchf√ºhren eines weiteren Vergleichs

1. Probieren Sie das folgende Puzzle mit beiden Modellen aus, bitten Sie die Modelle, ihre Begr√ºndung zu erkl√§ren (die richtige Antwort ist 40!):

    ```
    I have 53 socks in my drawer: 21 identical blue, 15 identical black and 17 identical red. The lights are out, and it is completely dark. How many socks must I take out to make 100 percent certain I have at least one pair of black socks?
    ```

## Reflektieren der Modelle

Sie haben zwei Modelle verglichen, die sich sowohl in ihrer F√§higkeit, angemessene Reaktionen zu generieren, als auch in ihren Kosten unterscheiden k√∂nnen. In jedem generativen Szenario m√ºssen Sie ein Modell finden, das die richtige Balance zwischen der Eignung f√ºr die Aufgabe, die Sie ihm √ºbertragen m√∂chten, und den Kosten f√ºr die Nutzung des Modells f√ºr die Anzahl der Anfragen, die es voraussichtlich bearbeiten muss, bietet.

Die im Modellkatalog enthaltenen Details und Benchmarks sowie die M√∂glichkeit, Modelle visuell zu vergleichen, bieten einen n√ºtzlichen Ausgangspunkt f√ºr die Identifizierung von Kandidatenmodellen f√ºr eine generative KI-L√∂sung. Anschlie√üend k√∂nnen Sie Kandidatenmodelle mit einer Vielzahl von System- und Benutzerprompts im Chat-Playground testen.

## Bereinigen

Wenn Sie die Erkundung des Azure KI-Foundry-Portals abgeschlossen haben, sollten Sie die Ressourcen, die Sie in dieser √úbung erstellt haben, l√∂schen, um unn√∂tige Azure-Kosten zu vermeiden.

1. √ñffnen Sie das [Azure-Portal](https://portal.azure.com), und zeigen Sie den Inhalt der Ressourcengruppe an, in der Sie die in dieser √úbung verwendeten Ressourcen bereitgestellt haben.
1. W√§hlen Sie auf der Symbolleiste die Option **Ressourcengruppe l√∂schen** aus.
1. Geben Sie den Namen der Ressourcengruppe ein, und best√§tigen Sie, dass Sie sie l√∂schen m√∂chten.
